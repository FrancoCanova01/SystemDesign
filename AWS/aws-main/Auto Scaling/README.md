# Auto Scaling

- For **horizontal scaling** there are **two solutions**: **ELBs (see ELB folder) and Auto Scaling**
- Used to scale out or scale in EC2 instances.
- Launch config includes AMI, instance type, user data, EBS volumes, SGs and SSH key pairs.
- You **scale upon rules or cloudwatch alarm or by even custom metrics**.
- **IAM roles that are set to ASGs are automatically set to underlying EC2 instances**.
- ASGs work well together with LBs for health checks.
- **ASGs can be Cross-AZ**
- **Auto Scaling groups cannot span across multiple Regions**.
- You can only specify **one launch configuration for an Auto Scaling group** at a time, and you **can't modify a launch configuration after you've created it**. To change the launch configuration for an Auto Scaling group, you must create a launch configuration and then update your Auto Scaling group with it.
- Health checks:
    - When one Availability Zone becomes unhealthy or unavailable, Auto Scaling launches new instances in an unaffected Availability Zone. When the unhealthy Availability Zone returns to a healthy state, Auto Scaling automatically **redistributes the application instances evenly across all of the designated Availability Zones**.
    - **Instances are assumed to be healthy** unless Amazon EC2 Auto Scaling receives notification that they are unhealthy.
    - The health status of an Auto Scaling **instance is either healthy or unhealthy**. This notification can come from one or more of the following sources: Amazon EC2, Elastic Load Balancing, or a custom health check. After Amazon EC2 Auto Scaling detects that an instance is unhealthy, it **terminates that instance and launches a new one**.
    ![ASG Health Checks](../media/asg-health-checks.png)
    - When Amazon EC2 Auto Scaling determines that an InService instance is unhealthy, it terminates the instance while it launches a new instance in replacement. The new instance launches using the current settings of the Auto Scaling group and its associated launch template or launch configuration.
    - Amazon EC2 Auto Scaling creates a new scaling activity for terminating the unhealthy instance and then terminates it. While the instance is terminating, another scaling activity launches a new instance.
    - Amazon EC2 Auto Scaling **only replaces 10 percent of the Auto Scaling group's desired capacity at a time**. It does this until all of the unhealthy instances are replaced. If the size of an Auto Scaling group is small enough that the resulting value of 10 percent is less than one, Amazon EC2 Auto Scaling replaces the unhealthy instances one at a time instead. This might result in some downtime for the group.
    - When replacing instances, it **waits for the new instances to pass an initial health check**. It **also waits for the instance warmup and health check grace period to finish before continuing with other unhealthy instances**.
    - The **HealthCheckGracePeriod** parameter for the Auto Scaling group helps Amazon EC2 Auto Scaling **distinguish unhealthy instances from newly launched instances that are not yet ready to serve traffic**. This grace period can prevent Amazon EC2 Auto Scaling from marking InService instances as unhealthy and terminating them before they have time to finish initializing. By default, the health check grace period is **300 seconds when you create an Auto Scaling group from the AWS Management Console**. Its default value is **0 seconds when you create an Auto Scaling group using the AWS CLI or an SDK** **(WATCH OUT WITH THIS!!)**. Set the health check grace period value greater than or equal to the maximum amount of startup time that your application needs. Startup time begins when an instance starts and ends when it can receive traffic.
    - Amazon EC2 Auto Scaling **does not perform health checks** on instances that are in the **Standby state**
    - Similarly, **when your instance is terminated**, its attached **EBS volumes are detached** (or deleted depending on the volume's DeleteOnTermination attribute). You must manually attach these EBS volumes to the new instance, or do it automatically with a lifecycle hook-based solution
- **Scaling Cooldowns**: Wait for previous scaling policy activity to take place before launching a new scaling task. You can create cooldowns that apply to specific simple scaling policies. You may also want to use this in scale in policies so ASG takes less time to determine ir further scale in is needed to satisfy a certain criteria. The **default cooldown is 300 seconds**. Cooldown periods help to **prevent the initiation of additional scaling activities before the effects of previous activities are visible**.
- **Scaling Policies**:
    - **Manual scaling**:
        - You can either update the **desired capacity** of the Auto Scaling group, or **update the instances** that are attached to the Auto Scaling group.
    - **Dynamic scaling**: Track a specific CloudWatch metric, and it defines what action to take when the associated CloudWatch alarm is in ALARM. The **metrics that are used to trigger an alarm are an aggregation of metrics coming from all of the instances in the Auto Scaling group**. When a dynamic scaling policy is invoked, if the capacity calculation produces a number outside of the minimum and maximum size range of the group, Amazon EC2 Auto Scaling ensures that the **new capacity never goes outside of the minimum and maximum size limits (except in cases where weighted instances are enabled)**
        - **Target tracking scaling**: Select a scaling metric and set a target value. Amazon EC2 Auto Scaling creates and manages the CloudWatch alarms that trigger the scaling policy and **calculates the scaling adjustment based on the metric and the target value**. The scaling policy adds or removes capacity as required to **keep the metric at, or close to, the specified target value**. The value used as metric must be such that it increases or decreases proportionally to the number of instances in the ASG. A target tracking scaling policy assumes that it should scale out your Auto Scaling group when the specified metric is above the target value. You cannot use a target tracking scaling policy to scale out your Auto Scaling group when the specified metric is below the target value.
        - **Step scaling / Simple scaling:** Using CloudWatch alarms. **More control over scale in and out by specifying amount of new EC2s to create/terminate based on a metric that changes to ALARM state.** The adjustments to be performed in the ASG must vary based on the size of the alarm breach. Both require you to create CloudWatch alarms for the scaling policies. Both require you to specify the high and low thresholds for the alarms. Both require you to define whether to add or remove instances, and how many, or set the group to an exact size. The main difference between the policy types is the step adjustments that you get with step scaling policies.
            - With **simple scaling** after a scaling activity is started, the **policy must wait for the scaling activity or health check replacement to complete and the cooldown period to end before responding to additional alarms**.
            - With **step scaling the policy can continue to respond to additional alarms**, even while a scaling activity or health check replacement is in progress. Therefore, all alarms that are breached are evaluated by Amazon EC2 Auto Scaling as it receives the alarm messages.
                - **Specify one or more step adjustments that automatically scale** the number of instances dynamically based on the size of the alarm breach.
    - **Scheduled Actions**
    - **Predictive Scheduling**: Use predictive scaling to increase the number of EC2 instances in your Auto Scaling group in advance of daily and weekly patterns in traffic flows. Predictive scaling can help you scale faster by launching capacity in advance of forecasted load, compared to using only dynamic scaling, which is reactive in nature. Predictive scaling **uses machine learning to predict capacity requirements based on historical data from CloudWatch.** The machine learning algorithm consumes the available historical data and calculates capacity that best fits the historical load pattern, and then continuously learns based on new data to make future forecasts more accurate.
- **Lifecycle Hooks**: Used to **perform an action before or after instances launch and terminate**. The action is performed once instance is launched and before it is assigned to the group or when it it terminated after de-registering from the group. **The default max time an instance can be in lifecycle hook mode (i.e: Wait states) is one hour.**
    - Notes:
        - If the Auto Scaling group is being used with Elastic Load Balancing, the terminating instance is first deregistered from the load balancer. If connection draining is enabled for the load balancer, the instance stops accepting new connections and waits for existing connections to drain before completing the deregistration process.

![ASG Lifecycle hooks](../media/asg-lifecycle-hooks.png)

- **Enter and Exit Standby**: You can **put instances from "In Service" to "Standby" state**. This removes instance form service to troubleshoot, make changes to it, and then put it back in service.
    - Notes:
        - If using a ALB or CLB, and connection draining is enabled for the load balancer, Elastic Load Balancing waits 300 seconds by default before completing the deregistration process, which helps in-flight requests to complete.
        - The value that you specified as your **desired capacity is decremented when you put an instance on standby**. If you specify this option, the Auto Scaling group launches an instance to replace the one on standby. **Alternatively, you can specify that your desired capacity is not decremented**. This prevents the launch of an additional instance while you have this instance on standby. The intention is to help you maintain capacity for your application while one or more instances are on standby.
        - After you put an instance that was on standby back in service, the desired capacity is incremented. If you did not decrement the capacity when you put the instance on standby, the Auto Scaling group detects that you have more instances than you need. It applies the termination policy in effect to reduce the size of the group.

![ASG Standby](../media/asg-standby.png)

- Warm pools:
    - A warm pool gives you the **ability to decrease latency for your applications that have exceptionally long boot times**, for example, because instances need to write massive amounts of data to disk. With warm pools, you no longer have to over-provision your Auto Scaling groups to manage latency in order to improve application performance.
    - A warm pool is a pool of **pre-initialized EC2 instances that sits alongside an Auto Scaling group**
    - By default, **the size of the warm pool is calculated as the difference between the Auto Scaling group's maximum capacity and its desired capacity**. You can keep instances in the warm pool in one of three states: **Stopped, Running, or Hibernated (use Stop or Hibernated to reduce costs, the latter retains RAM state in disk ready for when it is started)**.

- **Instance weighting**: By default, all instance types are treated with the same weight. In other words, ASG launches a large or small instance type instance and that instance counts towards the groups desired capacity. You can **weight your instances to suit your specific application needs, for example, by the cores (vCPUs) or by memory (GiBs)**. With instance weighing, you can assign a number value that specifies how many capacity units to associate with each instance type. With weighing, **your ASG can scale out ABOVE THE MAXIMUM SIZE LIMIT, but only by up to your maximum instance weight.**

## Notes from practice tests

- Scaling actions always leave you above min capacity and below max capacity. **The exception is when you use instance weighting**. In this case, Amazon EC2 Auto Scaling can scale out above the maximum size limit, but only by up to your maximum instance weight. Its intention is to get as close to the new desired capacity as possible but still adhere to the allocation strategies that are specified for the group. The allocation strategies determine which instance types to launch. The weights determine how many capacity units each instance contributes to the desired capacity of the group based on its instance type.
    - Example 3: An Auto Scaling group has a maximum capacity of 12, a current capacity of 10, and a dynamic scaling policy that adds 5 capacity units. Instance types have one of three weights assigned: 1, 4, or 6. When invoking the policy, Amazon EC2 Auto Scaling chooses to launch an instance type with a weight of 6 based on the allocation strategy. The result of this scale-out event is a group with a desired capacity of 12 and a current capacity of 16.

- For an advanced scaling configuration, **your Auto Scaling group can have more than one scaling policy**. For example, you can define one or more target tracking scaling policies, one or more step scaling policies, or both. This provides greater flexibility to cover multiple scenarios. To illustrate how multiple dynamic scaling policies work together, consider an application that uses an Auto Scaling group and an Amazon SQS queue to send requests to a single EC2 instance. To help ensure that the application performs at optimum levels, there are two policies that control when the Auto Scaling group should scale out. One is a target tracking policy that uses a custom metric to add and remove capacity based on the number of SQS messages in the queue. The other is a step scaling policy that uses the Amazon CloudWatch CPUUtilization metric to add capacity when the instance exceeds 90 percent utilization for a specified length of time. **When there are multiple policies in force at the same time, there's a chance that each policy could instruct the Auto Scaling group to scale out (or in) at the same time.** For example, it's possible that the CPUUtilization metric spikes and triggers the CloudWatch alarm at the same time that the SQS custom metric spikes and triggers the custom metric alarm. **When these situations occur, Amazon EC2 Auto Scaling chooses the policy that provides the largest capacity for both scale out and scale in.** Suppose, for example, that the policy for CPUUtilization launches one instance, while the policy for the SQS queue launches two instances. If the scale-out criteria for both policies are met at the same time, Amazon EC2 Auto Scaling gives precedence to the SQS queue policy. This results in the Auto Scaling group launching two instances.

- ASGs monitoring
    - **By default, basic monitoring is enabled** when you create a launch template or when you use the **AWS Management Console** to create a launch configuration. This could be the reason behind only the basic monitoring taking place.
    - **Detailed monitoring is enabled by default** when you create a launch configuration using the **AWS CLI or an SDK**.

- [EC2 Instance Health Check vs ELB Health Check vs Auto Scaling and Custom Health Check](https://tutorialsdojo.com/ec2-instance-health-check-vs-elb-health-check-vs-auto-scaling-and-custom-health-check/?src=udemy)